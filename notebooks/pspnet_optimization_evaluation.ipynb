{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARrePr2ZfxlU","outputId":"30f729ac-2417-4899-b929-7dfcd745263f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install imagecodecs\n","!pip install segmentation-models-pytorch\n","!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYJEZKpIJXFd","outputId":"cb9ff46c-e149-43f6-ef9f-cd61953d1a4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (2025.3.30)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagecodecs) (2.0.2)\n","Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.11/dist-packages (0.5.0)\n","Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.31.2)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.0.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.2.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\n","Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.15)\n","Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.4.26)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import skimage.io\n","import torch\n","import torch.nn as nn\n","from torchvision.transforms import Compose, Resize, Grayscale\n","import imagecodecs\n","from pathlib import Path\n","import os\n","import optuna\n","import segmentation_models_pytorch as smp\n","from tensorflow import keras\n","import zipfile"],"metadata":{"id":"TFOZojfyJll0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ToFloat():\n","    def __call__(self, x):\n","        return x.astype(np.float32)\n","\n","class ToTensor():\n","    def __call__(self, x):\n","        if len(x.shape) == 2:\n","            return torch.from_numpy(x.copy()).unsqueeze(0)\n","        elif len(x.shape) == 3:\n","            if x.shape[2]==3:\n","              return torch.permute(torch.from_numpy(x.copy()),(2,0,1))\n","            else:\n","              return torch.from_numpy(x.copy())\n","class RePermute():\n","    def __call__(self, x):\n","        if len(x.shape) == 3:\n","          if x.shape[0]==1:\n","            return torch.permute(x,(1,2,0))\n","        return x\n","\n","\n","\n","class Normalize():\n","    def __init__(self, min=None, max =None, eps=1e-8):\n","        self.min = min\n","        self.max = max\n","        self.eps = eps\n","\n","    def __call__(self, x):\n","        if self.min is not None and self.max is not None:\n","            return (x - self.min) / (self.max - self.min + self.eps)\n","        else:\n","            return (x - x.min()) / (x.max() - x.min() + self.eps)\n","\n","\n","class Instance2Semantic():\n","    \"\"\"\n","    Converts instance segmentation masks into binary foreground/background masks\n","    \"\"\"\n","    def __call__(self, x, threshold=0.5):\n","        return (x > threshold).astype(int)\n","\n","# class to change cut image to square\n","class MakeSquare():\n","  def __call__(self, x):\n","      h, w = x.shape[:2]\n","      dh,dw =0,0\n","      m=h\n","      if h>w:\n","        dh=h-w\n","        m=w\n","      else:\n","        dw=w-h\n","        m=h\n","      a, b = np.random.randint(0, dh) if dh > 0 else 0, np.random.randint(0, dw) if dw > 0 else 0\n","      slices = (\n","            slice(a, a + m),\n","            slice(b, b + m)\n","      )\n","      x = x[slices]\n","      return x\n","\n","def image_to_square(im,label,s = 480,transform = False):\n","  im = MakeSquare()(im)\n","  label=MakeSquare()(label)\n","\n","  image_transforms = Compose([\n","    ToFloat(),\n","    ToTensor(),\n","    Grayscale(1),\n","    Resize((s,s)),\n","    RePermute(),\n","    Normalize(), # min=0, max=255\n","  ])\n","  label_transforms = Compose([\n","      Instance2Semantic(),\n","      ToTensor(),\n","      Resize((s,s)),\n","      RePermute()\n","  ])\n","  if transform:\n","    return image_transforms(im), label_transforms(label)\n","\n","  return im, label\n","\n","def create_dataset(\n","    dataset_dir, sequenc=\"images\", labels=\"labels\"):\n","    \"\"\"\n","    Load images and masks from a dataset directory.\n","    \"\"\"\n","    # create directory names\n","    img_dir = dataset_dir / sequenc\n","    msk_dir =  dataset_dir / labels\n","    # find out which frames have provided masks\n","\n","    nf = sorted(os.listdir(img_dir))\n","    nf = [f\"{img_dir}/{x}\" for x in nf]\n","    frames =[]\n","    for f in nf:\n","      if \".tif\" in f:\n","        frames.append(f)\n","\n","    mask = [f\"{msk_dir}/{x}\" for x in sorted(os.listdir(msk_dir))]\n","    mask_list=[]\n","    for f in mask:\n","      if \".tif\" in f:\n","        mask_list.append(f)\n","\n","\n","    # load images and masks\n","    images = [\n","        skimage.io.imread(fp)\n","        for fp in frames\n","    ]\n","    masks = [\n","        skimage.io.imread(fp)\n","        for fp in mask_list\n","    ]\n","    for i in range(len(images)):\n","      im,lab = image_to_square(images[i],masks[i],transform=True)\n","      images[i]=im.squeeze()\n","      masks[i]=lab.squeeze()\n","\n","    return np.stack(images), np.stack(masks)"],"metadata":{"id":"1iiRt_ZAJiTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_training=\"drive/MyDrive/DeepLife/Training.zip\"\n","path_to_test = \"drive/MyDrive/DeepLife/Tuning_preprocessed.zip\"\n","data_dir=\"data\"\n","!mkdir data_dir\n","\n","#\"\"\"\n","z = zipfile.ZipFile(path_to_test)\n","z.extractall(data_dir)\n","#\"\"\"\n","z = zipfile.ZipFile(path_to_training)\n","z.extractall(data_dir)\n","#\"\"\"\n","\n","x_test, y_test = create_dataset(Path(f\"{data_dir}/Tuning\"), \"images\", \"labels\")\n","x_train, y_train = create_dataset(Path(f\"{data_dir}/Training\"), \"images\", \"labels\")\n","X_val = x_train[-20:]\n","X_train = x_train[:-20]\n","y_val = y_train[-20:]\n","y_train = y_train[:-20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed3wItJTIq-4","outputId":"75dadf77-3b4b-4184-bc92-c859bfda4196"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘data_dir’: File exists\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UoNEs-vufWbx","outputId":"8dd7119e-4c3b-431f-e178-639bef0ebbc3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:40:36,757] A new study created in memory with name: no-name-068ebfc8-04e3-44c7-9baf-b6fdb3bfa999\n"]},{"output_type":"stream","name":"stdout","text":["Using CUDA\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-943d1ab29eb5>:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n","<ipython-input-6-943d1ab29eb5>:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  dropout = trial.suggest_uniform('dropout', 0.0, 0.5)\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Val Loss: 0.5867, Val Accuracy: 0.9050\n","Epoch 2/10, Val Loss: 0.3242, Val Accuracy: 0.9170\n","Epoch 3/10, Val Loss: 0.2207, Val Accuracy: 0.9214\n","Epoch 4/10, Val Loss: 0.1938, Val Accuracy: 0.9242\n","Epoch 5/10, Val Loss: 0.1884, Val Accuracy: 0.9253\n","Epoch 6/10, Val Loss: 0.1809, Val Accuracy: 0.9308\n","Epoch 7/10, Val Loss: 0.1740, Val Accuracy: 0.9345\n","Epoch 8/10, Val Loss: 0.1674, Val Accuracy: 0.9370\n","Epoch 9/10, Val Loss: 0.1639, Val Accuracy: 0.9379\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:41:53,707] Trial 0 finished with value: -0.9364856770833333 and parameters: {'lr': 2.4819647128070413e-05, 'dropout': 0.23246865879648398, 'batch_size': 32}. Best is trial 0 with value: -0.9364856770833333.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1633, Val Accuracy: 0.9365\n","New best model saved with validation accuracy: 0.9365\n","Epoch 1/10, Val Loss: 0.2403, Val Accuracy: 0.9250\n","Epoch 2/10, Val Loss: 0.2367, Val Accuracy: 0.9270\n","Epoch 3/10, Val Loss: 0.1444, Val Accuracy: 0.9357\n","Epoch 4/10, Val Loss: 0.2288, Val Accuracy: 0.9219\n","Epoch 5/10, Val Loss: 0.2019, Val Accuracy: 0.9244\n","Epoch 6/10, Val Loss: 0.1966, Val Accuracy: 0.9265\n","Epoch 7/10, Val Loss: 0.1589, Val Accuracy: 0.9323\n","Epoch 8/10, Val Loss: 0.2153, Val Accuracy: 0.9279\n","Epoch 9/10, Val Loss: 0.2072, Val Accuracy: 0.9288\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:43:14,453] Trial 1 finished with value: -0.9308600260416666 and parameters: {'lr': 0.00021244511660353622, 'dropout': 0.31875869556846964, 'batch_size': 8}. Best is trial 0 with value: -0.9364856770833333.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2027, Val Accuracy: 0.9309\n","Epoch 1/10, Val Loss: 0.2395, Val Accuracy: 0.9167\n","Epoch 2/10, Val Loss: 0.1949, Val Accuracy: 0.9268\n","Epoch 3/10, Val Loss: 0.1911, Val Accuracy: 0.9296\n","Epoch 4/10, Val Loss: 0.1817, Val Accuracy: 0.9406\n","Epoch 5/10, Val Loss: 0.1796, Val Accuracy: 0.9386\n","Epoch 6/10, Val Loss: 0.1791, Val Accuracy: 0.9386\n","Epoch 7/10, Val Loss: 0.1691, Val Accuracy: 0.9426\n","Epoch 8/10, Val Loss: 0.1765, Val Accuracy: 0.9438\n","Epoch 9/10, Val Loss: 0.1671, Val Accuracy: 0.9411\n","Epoch 10/10, Val Loss: 0.1638, Val Accuracy: 0.9424\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:44:35,214] Trial 2 finished with value: -0.9423858506944445 and parameters: {'lr': 2.7087564168087105e-05, 'dropout': 0.20524806681085656, 'batch_size': 8}. Best is trial 2 with value: -0.9423858506944445.\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation accuracy: 0.9424\n","Epoch 1/10, Val Loss: 0.2164, Val Accuracy: 0.9309\n","Epoch 2/10, Val Loss: 0.2030, Val Accuracy: 0.9217\n","Epoch 3/10, Val Loss: 0.1971, Val Accuracy: 0.9248\n","Epoch 4/10, Val Loss: 0.2081, Val Accuracy: 0.9217\n","Epoch 5/10, Val Loss: 0.1973, Val Accuracy: 0.9240\n","Epoch 6/10, Val Loss: 0.2082, Val Accuracy: 0.9225\n","Epoch 7/10, Val Loss: 0.2031, Val Accuracy: 0.9242\n","Epoch 8/10, Val Loss: 0.2007, Val Accuracy: 0.9258\n","Epoch 9/10, Val Loss: 0.1995, Val Accuracy: 0.9267\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:45:55,788] Trial 3 finished with value: -0.924740234375 and parameters: {'lr': 1.716005281502582e-05, 'dropout': 0.394336533743989, 'batch_size': 8}. Best is trial 2 with value: -0.9423858506944445.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2093, Val Accuracy: 0.9247\n","Epoch 1/10, Val Loss: 0.1994, Val Accuracy: 0.9247\n","Epoch 2/10, Val Loss: 1.6470, Val Accuracy: 0.0913\n","Epoch 3/10, Val Loss: 5.0205, Val Accuracy: 0.0834\n","Epoch 4/10, Val Loss: 0.1858, Val Accuracy: 0.9399\n","Epoch 5/10, Val Loss: 0.4148, Val Accuracy: 0.9328\n","Epoch 6/10, Val Loss: 0.3262, Val Accuracy: 0.9347\n","Epoch 7/10, Val Loss: 0.2237, Val Accuracy: 0.9412\n","Epoch 8/10, Val Loss: 0.2134, Val Accuracy: 0.9286\n","Epoch 9/10, Val Loss: 0.2173, Val Accuracy: 0.9326\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:47:12,876] Trial 4 finished with value: -0.9381890190972222 and parameters: {'lr': 0.0028955791811950873, 'dropout': 0.22805461985148295, 'batch_size': 32}. Best is trial 2 with value: -0.9423858506944445.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1961, Val Accuracy: 0.9382\n","Epoch 1/10, Val Loss: 0.1656, Val Accuracy: 0.9402\n","Epoch 2/10, Val Loss: 0.1541, Val Accuracy: 0.9424\n","Epoch 3/10, Val Loss: 0.2316, Val Accuracy: 0.8752\n","Epoch 4/10, Val Loss: 0.2806, Val Accuracy: 0.9231\n","Epoch 5/10, Val Loss: 0.3132, Val Accuracy: 0.9265\n","Epoch 6/10, Val Loss: 0.1572, Val Accuracy: 0.9355\n","Epoch 7/10, Val Loss: 0.7888, Val Accuracy: 0.5432\n","Epoch 8/10, Val Loss: 0.2494, Val Accuracy: 0.9413\n","Epoch 9/10, Val Loss: 0.5483, Val Accuracy: 0.6359\n","Epoch 10/10, Val Loss: 0.1483, Val Accuracy: 0.9437\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:48:29,827] Trial 5 finished with value: -0.9437094184027778 and parameters: {'lr': 0.0020349562973087745, 'dropout': 0.29404550956330694, 'batch_size': 16}. Best is trial 5 with value: -0.9437094184027778.\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation accuracy: 0.9437\n","Epoch 1/10, Val Loss: 0.1820, Val Accuracy: 0.9400\n","Epoch 2/10, Val Loss: 0.2127, Val Accuracy: 0.9235\n","Epoch 3/10, Val Loss: 0.2027, Val Accuracy: 0.9270\n","Epoch 4/10, Val Loss: 0.2205, Val Accuracy: 0.9228\n","Epoch 5/10, Val Loss: 0.2237, Val Accuracy: 0.9238\n","Epoch 6/10, Val Loss: 0.2099, Val Accuracy: 0.9259\n","Epoch 7/10, Val Loss: 0.2298, Val Accuracy: 0.9237\n","Epoch 8/10, Val Loss: 0.2221, Val Accuracy: 0.9256\n","Epoch 9/10, Val Loss: 0.2267, Val Accuracy: 0.9254\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:49:50,531] Trial 6 finished with value: -0.9274958767361111 and parameters: {'lr': 1.771328137537551e-05, 'dropout': 0.10069328027908131, 'batch_size': 8}. Best is trial 5 with value: -0.9437094184027778.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2178, Val Accuracy: 0.9275\n","Epoch 1/10, Val Loss: 0.2773, Val Accuracy: 0.9273\n","Epoch 2/10, Val Loss: 0.2085, Val Accuracy: 0.9254\n","Epoch 3/10, Val Loss: 0.2187, Val Accuracy: 0.9187\n","Epoch 4/10, Val Loss: 0.2130, Val Accuracy: 0.9184\n","Epoch 5/10, Val Loss: 0.2179, Val Accuracy: 0.9181\n","Epoch 6/10, Val Loss: 0.2135, Val Accuracy: 0.9191\n","Epoch 7/10, Val Loss: 0.2305, Val Accuracy: 0.9180\n","Epoch 8/10, Val Loss: 0.2341, Val Accuracy: 0.9184\n","Epoch 9/10, Val Loss: 0.2232, Val Accuracy: 0.9199\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:51:11,143] Trial 7 finished with value: -0.9201905381944444 and parameters: {'lr': 1.0712400912306693e-05, 'dropout': 0.044544082521131345, 'batch_size': 8}. Best is trial 5 with value: -0.9437094184027778.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2223, Val Accuracy: 0.9202\n","Epoch 1/10, Val Loss: 0.1688, Val Accuracy: 0.9444\n","Epoch 2/10, Val Loss: 0.2319, Val Accuracy: 0.9313\n","Epoch 3/10, Val Loss: 0.2173, Val Accuracy: 0.9448\n","Epoch 4/10, Val Loss: 0.1247, Val Accuracy: 0.9491\n","Epoch 5/10, Val Loss: 0.1927, Val Accuracy: 0.9452\n","Epoch 6/10, Val Loss: 0.1528, Val Accuracy: 0.9544\n","Epoch 7/10, Val Loss: 0.1510, Val Accuracy: 0.9536\n","Epoch 8/10, Val Loss: 0.1339, Val Accuracy: 0.9563\n","Epoch 9/10, Val Loss: 0.1491, Val Accuracy: 0.9477\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:52:27,985] Trial 8 finished with value: -0.9507588975694444 and parameters: {'lr': 0.0008596409333243392, 'dropout': 0.34178004983058724, 'batch_size': 16}. Best is trial 8 with value: -0.9507588975694444.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1376, Val Accuracy: 0.9508\n","New best model saved with validation accuracy: 0.9508\n","Epoch 1/10, Val Loss: 0.1996, Val Accuracy: 0.9439\n","Epoch 2/10, Val Loss: 0.1470, Val Accuracy: 0.9412\n","Epoch 3/10, Val Loss: 0.1410, Val Accuracy: 0.9440\n","Epoch 4/10, Val Loss: 0.1566, Val Accuracy: 0.9378\n","Epoch 5/10, Val Loss: 0.1469, Val Accuracy: 0.9415\n","Epoch 6/10, Val Loss: 0.1685, Val Accuracy: 0.9412\n","Epoch 7/10, Val Loss: 0.2259, Val Accuracy: 0.9367\n","Epoch 8/10, Val Loss: 0.1613, Val Accuracy: 0.9434\n","Epoch 9/10, Val Loss: 0.2190, Val Accuracy: 0.9341\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:53:48,541] Trial 9 finished with value: -0.9397113715277777 and parameters: {'lr': 7.949185669212524e-05, 'dropout': 0.40726966867496206, 'batch_size': 8}. Best is trial 8 with value: -0.9507588975694444.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2664, Val Accuracy: 0.9397\n","Epoch 1/10, Val Loss: 0.1858, Val Accuracy: 0.9330\n","Epoch 2/10, Val Loss: 0.2155, Val Accuracy: 0.9358\n","Epoch 3/10, Val Loss: 0.5290, Val Accuracy: 0.6695\n","Epoch 4/10, Val Loss: 0.1416, Val Accuracy: 0.9433\n","Epoch 5/10, Val Loss: 0.1346, Val Accuracy: 0.9515\n","Epoch 6/10, Val Loss: 0.1434, Val Accuracy: 0.9483\n","Epoch 7/10, Val Loss: 0.1240, Val Accuracy: 0.9576\n","Epoch 8/10, Val Loss: 0.1315, Val Accuracy: 0.9596\n","Epoch 9/10, Val Loss: 0.1398, Val Accuracy: 0.9511\n","Epoch 10/10, Val Loss: 0.1379, Val Accuracy: 0.9509\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:55:05,348] Trial 10 finished with value: -0.9508678385416667 and parameters: {'lr': 0.0007409417124346692, 'dropout': 0.48908734753672994, 'batch_size': 16}. Best is trial 10 with value: -0.9508678385416667.\n"]},{"output_type":"stream","name":"stdout","text":["New best model saved with validation accuracy: 0.9509\n","Epoch 1/10, Val Loss: 0.1384, Val Accuracy: 0.9460\n","Epoch 2/10, Val Loss: 0.2499, Val Accuracy: 0.8981\n","Epoch 3/10, Val Loss: 0.4467, Val Accuracy: 0.7492\n","Epoch 4/10, Val Loss: 0.1374, Val Accuracy: 0.9452\n","Epoch 5/10, Val Loss: 0.2128, Val Accuracy: 0.9464\n","Epoch 6/10, Val Loss: 0.1481, Val Accuracy: 0.9518\n","Epoch 7/10, Val Loss: 0.1310, Val Accuracy: 0.9532\n","Epoch 8/10, Val Loss: 0.1251, Val Accuracy: 0.9562\n","Epoch 9/10, Val Loss: 0.1341, Val Accuracy: 0.9497\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:56:21,945] Trial 11 finished with value: -0.9456716579861111 and parameters: {'lr': 0.0007014700062977945, 'dropout': 0.49757722030466583, 'batch_size': 16}. Best is trial 10 with value: -0.9508678385416667.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1346, Val Accuracy: 0.9457\n","Epoch 1/10, Val Loss: 0.8680, Val Accuracy: 0.5914\n","Epoch 2/10, Val Loss: 2.1150, Val Accuracy: 0.9186\n","Epoch 3/10, Val Loss: 0.5128, Val Accuracy: 0.9287\n","Epoch 4/10, Val Loss: 1.5421, Val Accuracy: 0.8891\n","Epoch 5/10, Val Loss: 0.5287, Val Accuracy: 0.8382\n","Epoch 6/10, Val Loss: 0.3726, Val Accuracy: 0.9190\n","Epoch 7/10, Val Loss: 0.4387, Val Accuracy: 0.9336\n","Epoch 8/10, Val Loss: 0.3130, Val Accuracy: 0.9396\n","Epoch 9/10, Val Loss: 0.4600, Val Accuracy: 0.9401\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:57:38,159] Trial 12 finished with value: -0.9373687065972223 and parameters: {'lr': 0.009262430799365945, 'dropout': 0.4840452252202024, 'batch_size': 16}. Best is trial 10 with value: -0.9508678385416667.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.3919, Val Accuracy: 0.9374\n","Epoch 1/10, Val Loss: 0.2287, Val Accuracy: 0.9411\n","Epoch 2/10, Val Loss: 0.1774, Val Accuracy: 0.9330\n","Epoch 3/10, Val Loss: 0.1591, Val Accuracy: 0.9561\n","Epoch 4/10, Val Loss: 0.1316, Val Accuracy: 0.9532\n","Epoch 5/10, Val Loss: 0.1429, Val Accuracy: 0.9503\n","Epoch 6/10, Val Loss: 0.1482, Val Accuracy: 0.9499\n","Epoch 7/10, Val Loss: 0.1667, Val Accuracy: 0.9480\n","Epoch 8/10, Val Loss: 0.1579, Val Accuracy: 0.9466\n","Epoch 9/10, Val Loss: 0.1636, Val Accuracy: 0.9457\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 18:58:55,062] Trial 13 finished with value: -0.9407126736111111 and parameters: {'lr': 0.0004466186998043572, 'dropout': 0.39365460544515757, 'batch_size': 16}. Best is trial 10 with value: -0.9508678385416667.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2305, Val Accuracy: 0.9407\n","Epoch 1/10, Val Loss: 0.2695, Val Accuracy: 0.9266\n","Epoch 2/10, Val Loss: 0.2566, Val Accuracy: 0.9379\n","Epoch 3/10, Val Loss: 0.2397, Val Accuracy: 0.9324\n","Epoch 4/10, Val Loss: 0.2745, Val Accuracy: 0.9345\n","Epoch 5/10, Val Loss: 0.1397, Val Accuracy: 0.9495\n","Epoch 6/10, Val Loss: 0.2846, Val Accuracy: 0.9325\n","Epoch 7/10, Val Loss: 0.1975, Val Accuracy: 0.9428\n","Epoch 8/10, Val Loss: 0.1319, Val Accuracy: 0.9461\n","Epoch 9/10, Val Loss: 0.3504, Val Accuracy: 0.9239\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 19:00:11,709] Trial 14 finished with value: -0.9530438368055556 and parameters: {'lr': 0.001321232630903497, 'dropout': 0.34615345880823367, 'batch_size': 16}. Best is trial 14 with value: -0.9530438368055556.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1349, Val Accuracy: 0.9530\n","New best model saved with validation accuracy: 0.9530\n","Epoch 1/10, Val Loss: 0.1231, Val Accuracy: 0.9542\n","Epoch 2/10, Val Loss: 0.1488, Val Accuracy: 0.9476\n","Epoch 3/10, Val Loss: 0.1968, Val Accuracy: 0.9384\n","Epoch 4/10, Val Loss: 0.1965, Val Accuracy: 0.9371\n","Epoch 5/10, Val Loss: 0.2053, Val Accuracy: 0.9382\n","Epoch 6/10, Val Loss: 0.2052, Val Accuracy: 0.9361\n","Epoch 7/10, Val Loss: 0.1877, Val Accuracy: 0.9361\n","Epoch 8/10, Val Loss: 0.1977, Val Accuracy: 0.9435\n","Epoch 9/10, Val Loss: 0.1890, Val Accuracy: 0.9375\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 19:01:28,435] Trial 15 finished with value: -0.9417135416666667 and parameters: {'lr': 0.00015143280129010334, 'dropout': 0.44066944298538197, 'batch_size': 16}. Best is trial 14 with value: -0.9530438368055556.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2292, Val Accuracy: 0.9417\n","Epoch 1/10, Val Loss: 0.1554, Val Accuracy: 0.9434\n","Epoch 2/10, Val Loss: 0.4465, Val Accuracy: 0.8343\n","Epoch 3/10, Val Loss: 0.2283, Val Accuracy: 0.9335\n","Epoch 4/10, Val Loss: 0.2293, Val Accuracy: 0.9304\n","Epoch 5/10, Val Loss: 0.4147, Val Accuracy: 0.9211\n","Epoch 6/10, Val Loss: 0.2129, Val Accuracy: 0.9257\n","Epoch 7/10, Val Loss: 0.1562, Val Accuracy: 0.9436\n","Epoch 8/10, Val Loss: 0.2057, Val Accuracy: 0.9400\n","Epoch 9/10, Val Loss: 0.1482, Val Accuracy: 0.9428\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 19:02:44,919] Trial 16 finished with value: -0.9430494791666667 and parameters: {'lr': 0.0020839943302864493, 'dropout': 0.18440196655920915, 'batch_size': 16}. Best is trial 14 with value: -0.9530438368055556.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1543, Val Accuracy: 0.9430\n","Epoch 1/10, Val Loss: 1.9381, Val Accuracy: 0.7001\n","Epoch 2/10, Val Loss: 0.7966, Val Accuracy: 0.6089\n","Epoch 3/10, Val Loss: 0.8939, Val Accuracy: 0.1416\n","Epoch 4/10, Val Loss: 0.9663, Val Accuracy: 0.1846\n","Epoch 5/10, Val Loss: 0.1596, Val Accuracy: 0.9474\n","Epoch 6/10, Val Loss: 0.1574, Val Accuracy: 0.9473\n","Epoch 7/10, Val Loss: 0.1923, Val Accuracy: 0.9472\n","Epoch 8/10, Val Loss: 0.6110, Val Accuracy: 0.6135\n","Epoch 9/10, Val Loss: 0.2975, Val Accuracy: 0.8144\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 19:04:01,437] Trial 17 finished with value: -0.6734418402777778 and parameters: {'lr': 0.003780587354562316, 'dropout': 0.35227302767411833, 'batch_size': 16}. Best is trial 14 with value: -0.9530438368055556.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.5771, Val Accuracy: 0.6734\n","Epoch 1/10, Val Loss: 0.1704, Val Accuracy: 0.9449\n","Epoch 2/10, Val Loss: 0.1596, Val Accuracy: 0.9509\n","Epoch 3/10, Val Loss: 0.1238, Val Accuracy: 0.9543\n","Epoch 4/10, Val Loss: 0.1293, Val Accuracy: 0.9511\n","Epoch 5/10, Val Loss: 0.1512, Val Accuracy: 0.9473\n","Epoch 6/10, Val Loss: 0.2155, Val Accuracy: 0.9316\n","Epoch 7/10, Val Loss: 0.1355, Val Accuracy: 0.9477\n","Epoch 8/10, Val Loss: 0.1412, Val Accuracy: 0.9480\n","Epoch 9/10, Val Loss: 0.1535, Val Accuracy: 0.9467\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 19:05:18,962] Trial 18 finished with value: -0.9473891059027778 and parameters: {'lr': 0.0010577928019661078, 'dropout': 0.44504003848208457, 'batch_size': 32}. Best is trial 14 with value: -0.9530438368055556.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.1275, Val Accuracy: 0.9474\n","Epoch 1/10, Val Loss: 2.0185, Val Accuracy: 0.6370\n","Epoch 2/10, Val Loss: 0.4279, Val Accuracy: 0.9441\n","Epoch 3/10, Val Loss: 0.3165, Val Accuracy: 0.9598\n","Epoch 4/10, Val Loss: 0.3084, Val Accuracy: 0.9177\n","Epoch 5/10, Val Loss: 0.1592, Val Accuracy: 0.9618\n","Epoch 6/10, Val Loss: 0.3057, Val Accuracy: 0.8932\n","Epoch 7/10, Val Loss: 0.4973, Val Accuracy: 0.9193\n","Epoch 8/10, Val Loss: 0.2847, Val Accuracy: 0.9265\n","Epoch 9/10, Val Loss: 0.4141, Val Accuracy: 0.8772\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-05-15 19:06:35,331] Trial 19 finished with value: -0.9460225694444444 and parameters: {'lr': 0.008193719916519128, 'dropout': 0.16065411690461734, 'batch_size': 16}. Best is trial 14 with value: -0.9530438368055556.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Val Loss: 0.2275, Val Accuracy: 0.9460\n","Best hyperparameters: {'lr': 0.001321232630903497, 'dropout': 0.34615345880823367, 'batch_size': 16}\n","Best model state_dict saved to best_pspnet_model.pth\n"]}],"source":["# Define loss function and metrics outside the functions for reusability\n","loss_fn = torch.nn.BCEWithLogitsLoss()\n","\n","def create_pspnet(trial):\n","    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n","    dropout = trial.suggest_uniform('dropout', 0.0, 0.5)\n","    model = smp.PSPNet(\n","        encoder_name='resnet34',\n","        encoder_weights='imagenet',\n","        classes=1,\n","        activation=None, # Use None and apply sigmoid in loss or predictions\n","        dropout=dropout\n","    )\n","    # PyTorch models don't have a compile method like Keras\n","    # Define the optimizer here\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    return model, optimizer\n","\n","def objective(trial):\n","    global best_score\n","    # Get model and optimizer from create_pspnet\n","    model, optimizer = create_pspnet(trial)\n","\n","    # Move model to device\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    # Convert data to PyTorch tensors and move to device\n","    # Assuming X_train, y_train, X_val, y_val are numpy arrays\n","    # Add channel dimension for grayscale\n","    X_train_tensor = torch.from_numpy(X_train).float().unsqueeze(1).to(device)\n","    y_train_tensor = torch.from_numpy(y_train).float().unsqueeze(1).to(device)\n","    X_val_tensor = torch.from_numpy(X_val).float().unsqueeze(1).to(device)\n","    y_val_tensor = torch.from_numpy(y_val).float().unsqueeze(1).to(device)\n","\n","    # Duplicate the single channel to simulate a 3-channel RGB image for the encoder\n","    X_train_tensor = X_train_tensor.repeat(1, 3, 1, 1)\n","    X_val_tensor = X_val_tensor.repeat(1, 3, 1, 1)\n","\n","\n","    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n","    epochs = 10\n","\n","    # Simple manual training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        for i in range(0, len(X_train_tensor), batch_size):\n","            inputs = X_train_tensor[i:i+batch_size]\n","            labels = y_train_tensor[i:i+batch_size]\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Validation step\n","        model.eval()\n","        val_loss = 0\n","        val_correct = 0\n","        val_total = 0\n","        with torch.no_grad():\n","            for i in range(0, len(X_val_tensor), batch_size):\n","                inputs = X_val_tensor[i:i+batch_size]\n","                labels = y_val_tensor[i:i+batch_size]\n","\n","                outputs = model(inputs)\n","                val_loss += loss_fn(outputs, labels).item() * inputs.size(0)\n","\n","                # Calculate accuracy (example, adjust for segmentation)\n","                # For binary segmentation with BCEWithLogitsLoss and activation=None:\n","                predicted = (torch.sigmoid(outputs) > 0.5).float()\n","                val_correct += (predicted == labels).sum().item()\n","                val_total += labels.numel() # total number of pixels\n","\n","        avg_val_loss = val_loss / len(X_val_tensor)\n","        val_acc = val_correct / val_total\n","        print(f\"Epoch {epoch+1}/{epochs}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n","\n","    # Optuna optimizes based on validation metric\n","    # Save model if it's the best so far based on validation accuracy\n","    if 'best_score' not in globals() or val_acc > best_score: # Check if best_score is defined\n","        best_score = val_acc\n","        # Save the state_dict of the model\n","        # Make sure BEST_MODEL_PATH is defined\n","        if 'BEST_MODEL_PATH' in globals():\n","            torch.save(model.state_dict(), BEST_MODEL_PATH)\n","            print(f\"New best model saved with validation accuracy: {val_acc:.4f}\")\n","        else:\n","            print(\"BEST_MODEL_PATH is not defined. Cannot save the best model.\")\n","\n","\n","    # Optuna objective is typically to minimize, so return negative accuracy\n","    return -val_acc\n","\n","# Ensure CUDA is available if possible\n","if torch.cuda.is_available():\n","    print(\"Using CUDA\")\n","else:\n","    print(\"Using CPU\")\n","\n","# Define best_score and BEST_MODEL_PATH before calling optimize\n","best_score = -float('inf')\n","BEST_MODEL_PATH = 'best_pspnet_model.pth' # Use .pth extension for PyTorch models\n","\n","study = optuna.create_study(direction='minimize') # Use minimize since we return negative accuracy\n","study.optimize(objective, n_trials=20)\n","\n","print(\"Best hyperparameters:\", study.best_params)\n","print(f\"Best model state_dict saved to {BEST_MODEL_PATH}\")"]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"1fDAS8R0dUbF"}},{"cell_type":"code","source":[],"metadata":{"id":"6XXD6haodV6W"},"execution_count":null,"outputs":[]}]}